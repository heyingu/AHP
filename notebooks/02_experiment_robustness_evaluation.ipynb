{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bccfac-dd51-4d0c-9950-f4f7d0310cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 补丁1生效：已成功注入“全功能”伪模块。\n",
      ">>> 补丁2生效：已成功替换 nltk.download 函数。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ahp_env/lib/python3.12/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 恭喜！环境设置最终完成，所有模块导入成功！---\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# |      !!! 终极解决方案：“直捣黄龙”之最终极补丁 !!!             |\n",
    "# ====================================================================\n",
    "import sys\n",
    "import os\n",
    "from unittest.mock import patch\n",
    "import types\n",
    "from importlib.machinery import ModuleSpec\n",
    "\n",
    "# --- 补丁1：注入“全功能”伪模块 ---\n",
    "def create_full_fake_module(name, attributes_to_add):\n",
    "    spec = ModuleSpec(name, None)\n",
    "    module = types.ModuleType(name)\n",
    "    module.__spec__ = spec\n",
    "    for attr in attributes_to_add:\n",
    "        setattr(module, attr, lambda *args, **kwargs: None)\n",
    "    return module\n",
    "\n",
    "sys.modules['num2words'] = create_full_fake_module('num2words', ['num2words'])\n",
    "sys.modules['word2number'] = create_full_fake_module('word2number', ['w2n'])\n",
    "print(\">>> 补丁1生效：已成功注入“全功能”伪模块。\")\n",
    "\n",
    "# --- 补丁2：“直捣黄龙”，直接替换nltk.download函数 ---\n",
    "def dummy_nltk_download(*args, **kwargs):\n",
    "    print(\">>> 补丁2生效：已成功拦截并跳过 nltk.download() 调用！<<<\")\n",
    "    return True # 返回成功状态\n",
    "\n",
    "# 使用正确的函数路径进行替换\n",
    "patcher = patch('nltk.download', dummy_nltk_download)\n",
    "patcher.start()\n",
    "print(\">>> 补丁2生效：已成功替换 nltk.download 函数。\")\n",
    "\n",
    "\n",
    "# --- 补丁3：手动为NLTK“指路” ---\n",
    "nltk_data_dir = os.path.expanduser('~/nltk_data')\n",
    "import nltk\n",
    "if nltk_data_dir not in nltk.data.path:\n",
    "    nltk.data.path.append(nltk_data_dir)\n",
    "    print(f\"成功将 '{nltk_data_dir}' 添加到NLTK的搜索路径。\")\n",
    "\n",
    "# --- 补丁4：设置其他环境变量 ---\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false' \n",
    "sys.path.append('..')\n",
    "# ====================================================================\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- 正常导入所有模块 ---\n",
    "# 此时，所有已知的环境问题都已被我们的终极补丁修复\n",
    "from src.models.model_loader import load_main_llm\n",
    "from src.utils.data_loader import load_sst2_dataset\n",
    "from src.defenses import BasePredictor, NoDefense, AhpDefense, SelfDenoiseDefense\n",
    "from src.attacks import AttackerWrapper\n",
    "from src.utils.metrics import calculate_accuracy, calculate_asr\n",
    "\n",
    "print(\"\\n--- 恭喜！环境设置最终完成，所有模块导入成功！---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5798b0a-ae3f-4977-b9ae-583f1524b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 实验设置 ---\n",
    "TASK = 'sst2'\n",
    "DATASET_NAME = 'SST-2'\n",
    "NUM_SAMPLES_TO_TEST = 50 # 鲁棒性实验较慢，先用少量样本测试\n",
    "ATTACK_RECIPE = 'deepwordbug' # 'textbugger' 或 'deepwordbug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275d46a6-1594-43ad-8f3e-781c58dea9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载主模型: /root/autodl-tmp/vicuna-7b-v1.5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb344dbf270457c8272882e02f771a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主模型加载成功。\n",
      "正在加载SST-2数据集 (test split)...\n",
      "SST-2数据集加载成功。\n"
     ]
    }
   ],
   "source": [
    "# (单元格 2 - 最终修正)\n",
    "\n",
    "# --- 2. 加载模型和数据 ---\n",
    "local_model_path = \"/root/autodl-tmp/vicuna-7b-v1.5\"\n",
    "\n",
    "# ===================== 终极修正：关闭4-bit量化 =====================\n",
    "# 我们将使用全精度的float16模型，这将占用更多显存（约13-14GB）\n",
    "# 但这是让TextAttack正常工作的唯一方法。\n",
    "main_model, main_tokenizer = load_main_llm(model_name=local_model_path, use_4bit=False)\n",
    "# =============================================================\n",
    "\n",
    "dataset = load_sst2_dataset(split='test').select(range(NUM_SAMPLES_TO_TEST))\n",
    "dataset_df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e36ccc-0f53-4d6e-aac4-e3d5fda65754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载NLI模型: roberta-large-mnli...\n",
      "NLI模型加载成功。\n"
     ]
    }
   ],
   "source": [
    "# --- 3. 初始化防御策略和攻击器 ---\n",
    "\n",
    "# 创建基础预测器，所有防御和攻击都将基于它\n",
    "base_predictor = BasePredictor(main_model, main_tokenizer, task=TASK)\n",
    "\n",
    "# 定义要对比的防御策略\n",
    "defenses = {\n",
    "    \"No Defense (Baseline)\": NoDefense(base_predictor),\n",
    "    \"AHP-NLI Defense\": AhpDefense(base_predictor, k_val=3, m_val=10),\n",
    "    \"Self-Denoise Defense\": SelfDenoiseDefense(base_predictor, num_samples=10)\n",
    "}\n",
    "\n",
    "# ===================== 修正开始 =====================\n",
    "# 初始化攻击器时，应该传入我们创建好的 base_predictor 对象\n",
    "attacker = AttackerWrapper(base_predictor)\n",
    "# ===================== 修正结束 ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235a6c6b-ff1c-44f6-86a5-54f1ca013d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'src.attacks.attacks.ClassificationModelForAttack'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterSubstitution(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): LevenshteinEditDistance(\n",
      "        (max_edit_distance):  30\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 10 / 10: 100%|██████████| 10/10 [00:00<00:00, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[1 (52%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "uneasy mishmash of styles and genres .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[0 (54%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "this film 's relationship to actual tension is the same as what christmas-tree flocking in a spray can is to actual snow : a poor -- if durable -- imitation .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[1 (58%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "by the end of no such thing the audience , like beatrice , has a watchful affection for the monster .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[1 (53%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "director rob marshall went out gunning to make a great one .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[1 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "lathan and diggs have considerable personal charm , and their screen rapport makes the old story seem new .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[1 (58%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "a well-made and often lovely depiction of the mysteries of friendship .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[0 (54%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "none of this violates the letter of behan 's book , but missing is its spirit , its ribald , full-throated humor .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[0 (55%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "although it bangs a very cliched drum at times , this crowd-pleaser 's fresh dialogue , energetic music , and good-natured spunk are often infectious .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[1 (62%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "it is not a mass-market entertainment but an uncompromising attempt by one artist to think about another .\n",
      "\n",
      "\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[0 (50%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "this is junk food cinema at its greasiest .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+------+\n",
      "| Attack Results                |      |\n",
      "+-------------------------------+------+\n",
      "| Number of successful attacks: | 0    |\n",
      "| Number of failed attacks:     | 0    |\n",
      "| Number of skipped attacks:    | 10   |\n",
      "| Original accuracy:            | 0.0% |\n",
      "| Accuracy under attack:        | 0.0% |\n",
      "| Attack success rate:          | 0%   |\n",
      "| Average perturbed word %:     | nan% |\n",
      "| Average num. words per input: | 15.6 |\n",
      "| Avg num queries:              | nan  |\n",
      "+-------------------------------+------+\n",
      "正在使用 deepwordbug 生成对抗样本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/root/ahp_env/lib/python3.12/site-packages/textattack/metrics/attack_metrics/words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
      "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
      "/root/ahp_env/lib/python3.12/site-packages/numpy/_core/_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/root/ahp_env/lib/python3.12/site-packages/textattack/metrics/attack_metrics/attack_queries.py:39: RuntimeWarning: Mean of empty slice.\n",
      "  avg_num_queries = self.num_queries.mean()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958c3567ab2d454aab32bad34bc54199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TextAttack成功生成了 10 / 50 个对抗样本。\n",
      "已生成与原始数据对齐的完整对抗样本列表，长度为: 50\n"
     ]
    }
   ],
   "source": [
    "# (单元格 4 - 最终修正版)\n",
    "\n",
    "# --- 4. 生成对抗样本 ---\n",
    "# 注意：这一步会非常慢！\n",
    "adversarial_df = attacker.attack(dataset, attack_recipe_name=ATTACK_RECIPE)\n",
    "print(f\"\\nTextAttack成功生成了 {len(adversarial_df)} / {NUM_SAMPLES_TO_TEST} 个对抗样本。\")\n",
    "\n",
    "# --- 4.5. 对齐攻击数据 (关键修复) ---\n",
    "# 创建一个从“原始文本”到“对抗文本”的映射字典\n",
    "attack_map = pd.Series(adversarial_df.perturbed_text.values, index=adversarial_df.original_text).to_dict()\n",
    "\n",
    "# 创建一个与原始数据集(50个样本)完全对齐的、完整的对抗样本列表\n",
    "# 如果一个样本在attack_map中找不到，说明攻击失败或被跳过，我们就使用原始句子本身。\n",
    "full_perturbed_texts = [attack_map.get(sent, sent) for sent in dataset_df['sentence']]\n",
    "\n",
    "print(f\"已生成与原始数据对齐的完整对抗样本列表，长度为: {len(full_perturbed_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ecc6fd4-0233-4311-860a-f01b840b7b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 正在评估防御策略: No Defense (Baseline) ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1505c4deb04090916a49f569c079e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean Eval:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b73bc1e6e4a48a49265787a8670d98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Attack Eval:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dddf816089f4213927be6d4d7e471f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Baseline Eval:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 正在评估防御策略: AHP-NLI Defense ====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4138ca5aa0e24ceaaf98c29e3cf44478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean Eval:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beba3eca7b6d4f18ac0b6401945744af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487e9a8bd9754e11b7a08b5a23099c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64068ca671f643c39b47c08275bf0bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a842402bffce422cbe09c39854a5822f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f45a837a0ab4e259e763d6e534c8cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370ecc6d48734b709c60ee2ebdbc5641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f4d20da13c45fa95e6136875d25cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bcd4ab4b234796a599c5eb17ec47af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beab91c2e7d0444993f9ce7566b80ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2942389f285454fbfa1762c7a7905a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb35455760a4d68b885b1dd48e7a994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41de4a83faf48508b5017c3fb083770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8ce7b1ada149e0a0ec024c11d90c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef02e4047cd40c496f1a9600db3b82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b245a6b946413d84e5f41715801562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7497c6b9d80c42d29a441b2ae618f105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c89d3bb9b9c4f3baee108ab05dce4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc7ae1b2d354b05b477f7a5486ef43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a841d366394a0bab922f7790b485b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24500ad5af044f68bcabdf7cd0b6257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549852e51305419a8cdd8dc4a02bfdcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d6b645bcea4585984247aa9b8261b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefd0b4d8f9048d0bef29bde195d14df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b31d1dd3b54cdc94d23ed0e9460aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818fe046f4df44b78a635a79fcd8116f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cb88d80da8425789551313a0bf05eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdab2357ebc4f7dbfb3d9b5efc66f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f923b64604146b9a9d41351c8973140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02a238469ca4826abb8d9818ce51cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dd8d912dc3471fb3eb3bdffa7ba023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c18c591fbde467fb4eeb484afee51ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57a0fb2ddea4883973aebe4399517f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf32bb7c0ad4c41abf7530f59b0746a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6eb62e610d402c888d270629c972b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498970d48982424bb1793d2f5cf3dcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c91ce5d72c46eaa0190b51a8a5a37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fd866db72f4b74ba6a18fdeee86a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7e2d8a6dba446caf30b912535bda3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000610b36d2c493da0a58d58d6a465f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1026a33861a4d749094667bee3406aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating NLI Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m 正在评估防御策略: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdefense_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# a. 评估Clean Accuracy (在原始数据上)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m clean_preds = [\u001b[43mdefense_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset_df[\u001b[33m'\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m'\u001b[39m], desc=\u001b[33m\"\u001b[39m\u001b[33mClean Eval\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m     10\u001b[39m clean_accuracy = calculate_accuracy(dataset_df[\u001b[33m'\u001b[39m\u001b[33mlabel_text\u001b[39m\u001b[33m'\u001b[39m], clean_preds)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# b. 评估Accuracy under Attack (在对齐后的完整对抗样本上)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 使用我们新创建的 full_perturbed_texts 列表\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks/../src/defenses.py:78\u001b[39m, in \u001b[36mAhpDefense.__call__\u001b[39m\u001b[34m(self, sentence)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence):\n\u001b[32m     77\u001b[39m     masked_text = adversarial_masking(sentence, \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.tokenizer)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     candidates = \u001b[43mgenerate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mm_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     pruned_candidates = \u001b[38;5;28mself\u001b[39m.pruner.prune(sentence, candidates)\n\u001b[32m     80\u001b[39m     final_predictions = [\u001b[38;5;28mself\u001b[39m.predictor.predict(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m pruned_candidates]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/notebooks/../src/components/candidate_generation.py:25\u001b[39m, in \u001b[36mgenerate_candidates\u001b[39m\u001b[34m(masked_text, model, tokenizer, num_candidates, max_new_tokens)\u001b[39m\n\u001b[32m     22\u001b[39m inputs = tokenizer(prompt, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(model.device)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 防止过早停止\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# 解码并清理输出，只保留ASSISTANT:之后的部分\u001b[39;00m\n\u001b[32m     38\u001b[39m full_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ahp_env/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ahp_env/lib/python3.12/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ahp_env/lib/python3.12/site-packages/transformers/generation/utils.py:3260\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3257\u001b[39m beam_indices = running_beam_indices.detach().clone()\n\u001b[32m   3259\u001b[39m \u001b[38;5;66;03m# 4. run the generation loop\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3260\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_has_unfinished_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_peer_finished\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   3261\u001b[39m     \u001b[38;5;66;03m# a. Forward current tokens, obtain the logits\u001b[39;00m\n\u001b[32m   3262\u001b[39m     flat_running_sequences = \u001b[38;5;28mself\u001b[39m._flatten_beam_dim(running_sequences[:, :, :cur_len])\n\u001b[32m   3263\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(flat_running_sequences, **model_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ahp_env/lib/python3.12/site-packages/transformers/generation/utils.py:2583\u001b[39m, in \u001b[36mGenerationMixin._has_unfinished_sequences\u001b[39m\u001b[34m(self, this_peer_finished, synced_gpus, device)\u001b[39m\n\u001b[32m   2580\u001b[39m         result.past_key_values = result.past_key_values.to_legacy_cache()\n\u001b[32m   2581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_has_unfinished_sequences\u001b[39m(\u001b[38;5;28mself\u001b[39m, this_peer_finished: \u001b[38;5;28mbool\u001b[39m, synced_gpus: \u001b[38;5;28mbool\u001b[39m, device: torch.device) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   2584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2585\u001b[39m \u001b[33;03m    Returns whether there are still unfinished sequences in the device. The existence of unfinished sequences is\u001b[39;00m\n\u001b[32m   2586\u001b[39m \u001b[33;03m    fed through `this_peer_finished`. ZeRO stage 3-friendly.\u001b[39;00m\n\u001b[32m   2587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2588\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m synced_gpus:\n\u001b[32m   2589\u001b[39m         \u001b[38;5;66;03m# Under synced_gpus the `forward` call must continue until all gpus complete their sequence.\u001b[39;00m\n\u001b[32m   2590\u001b[39m         \u001b[38;5;66;03m# The following logic allows an early break if all peers finished generating their sequence\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# (单元格 5 - 最终修正版)\n",
    "\n",
    "results = []\n",
    "\n",
    "for defense_name, defense_method in defenses.items():\n",
    "    print(f\"\\n{'='*20} 正在评估防御策略: {defense_name} {'='*20}\")\n",
    "\n",
    "    # a. 评估Clean Accuracy (在原始数据上)\n",
    "    clean_preds = [defense_method(text) for text in tqdm(dataset_df['sentence'], desc=\"Clean Eval\")]\n",
    "    clean_accuracy = calculate_accuracy(dataset_df['label_text'], clean_preds)\n",
    "\n",
    "    # b. 评估Accuracy under Attack (在对齐后的完整对抗样本上)\n",
    "    # 使用我们新创建的 full_perturbed_texts 列表\n",
    "    attack_preds = [defense_method(text) for text in tqdm(full_perturbed_texts, desc=\"Attack Eval\")]\n",
    "    # 真实标签直接使用原始的、对齐的标签即可\n",
    "    attack_accuracy = calculate_accuracy(dataset_df['label_text'], attack_preds)\n",
    "\n",
    "    # c. 计算ASR\n",
    "    if \"baseline_clean_preds\" not in locals():\n",
    "        baseline_clean_preds = [defenses[\"No Defense (Baseline)\"](text) for text in tqdm(dataset_df['sentence'], desc=\"Baseline Eval\")]\n",
    "    \n",
    "    # 现在所有列表长度都为50，不再有IndexError\n",
    "    attack_success_rate = calculate_asr(baseline_clean_preds, attack_preds, dataset_df['label_text'].tolist())\n",
    "\n",
    "    results.append({\n",
    "        \"防御方法 (Defense)\": defense_name,\n",
    "        \"原始准确率 (Clean Acc)\": clean_accuracy,\n",
    "        \"攻击后准确率 (Attack Acc)\": attack_accuracy,\n",
    "        \"攻击成功率 (ASR)\": attack_success_rate\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3f90c5b-c5ed-4a66-809b-eb2c105a0a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "实验二：经验鲁棒性评估 - 结果汇总\n",
      "======================================================================\n",
      "       防御方法 (Defense)  原始准确率 (Clean Acc)  攻击后准确率 (Attack Acc)  攻击成功率 (ASR)\n",
      "No Defense (Baseline)               0.54                 0.54     0.000000\n",
      "      AHP-NLI Defense               0.56                 0.56     0.000000\n",
      " Self-Denoise Defense               0.56                 0.52     0.037037\n"
     ]
    }
   ],
   "source": [
    "# --- 6. 展示结果 ---\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n实验二：经验鲁棒性评估 - 结果汇总\")\n",
    "print(\"=\" * 70)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0d9304-3e1d-4964-a0eb-109537094277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "实验结果已成功保存到: ../results/experiment_2_robustness_deepwordbug.csv\n"
     ]
    }
   ],
   "source": [
    "# 保存结果\n",
    "if not os.path.exists('../results'):\n",
    "    os.makedirs('../results')\n",
    "save_path_exp2 = f'../results/experiment_2_robustness_{ATTACK_RECIPE}.csv'\n",
    "results_df.to_csv(save_path_exp2, index=False)\n",
    "print(f\"\\n实验结果已成功保存到: {save_path_exp2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e0ffcde-fcd7-4b21-a75d-aef362bb6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载NLtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca17ed9-1840-4cd4-9107-22f7c4d1e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import os\n",
    "# import zipfile\n",
    "\n",
    "# # =================================================================\n",
    "# # |          !!! 终极解决方案：启用AutoDL官方网络加速 !!!           |\n",
    "# # =================================================================\n",
    "\n",
    "# print(\"--- 正在启用AutoDL官方学术网络加速... ---\")\n",
    "# # 执行官方教程提供的命令，加载并应用代理设置到当前环境\n",
    "# result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "# output = result.stdout\n",
    "# for line in output.splitlines():\n",
    "#     if '=' in line:\n",
    "#         var, value = line.split('=', 1)\n",
    "#         os.environ[var] = value\n",
    "#         print(f\"成功设置环境变量: {var}\")\n",
    "\n",
    "# print(\"--- 网络加速已启用！开始下载NLTK数据包... ---\\n\")\n",
    "\n",
    "# # =================================================================\n",
    "\n",
    "# # --- NLTK数据将被保存到的路径 ---\n",
    "# nltk_data_path = os.path.expanduser('~/nltk_data')\n",
    "# print(f\"NLTK数据将被下载到: {nltk_data_path}\\n\")\n",
    "\n",
    "# # --- TextAttack所需的核心NLTK包列表 ---\n",
    "# packages_to_download = [\n",
    "#     ('averaged_perceptron_tagger', 'taggers'),\n",
    "#     ('stopwords', 'corpora'),\n",
    "#     ('omw-1.4', 'corpora'),\n",
    "#     ('universal_tagset', 'taggers'),\n",
    "#     ('wordnet', 'corpora'),\n",
    "#     ('punkt', 'tokenizers')\n",
    "# ]\n",
    "\n",
    "# # --- NLTK数据的官方下载源 (不再需要任何代理) ---\n",
    "# base_url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/\"\n",
    "\n",
    "# # --- 使用wget循环下载并解压 ---\n",
    "# for package, subdir in packages_to_download:\n",
    "    \n",
    "#     zip_url = f\"{base_url}{subdir}/{package}.zip\"\n",
    "#     zip_path = os.path.join(nltk_data_path, f\"{package}.zip\")\n",
    "#     extract_dir = os.path.join(nltk_data_path, subdir)\n",
    "#     final_path = os.path.join(extract_dir, package)\n",
    "\n",
    "#     if os.path.exists(final_path):\n",
    "#          print(f\"'{package}' 已存在，跳过。\")\n",
    "#          continue\n",
    "\n",
    "#     os.makedirs(extract_dir, exist_ok=True)\n",
    "    \n",
    "#     try:\n",
    "#         # --- 使用wget命令进行下载 (不再需要任何代理或证书参数) ---\n",
    "#         print(f\"--- 正在下载: {package} ---\")\n",
    "#         download_command = f\"wget -O {zip_path} {zip_url}\"\n",
    "        \n",
    "#         exit_code = os.system(download_command)\n",
    "        \n",
    "#         if exit_code != 0:\n",
    "#             raise ConnectionError(f\"wget下载失败，退出码: {exit_code}\")\n",
    "\n",
    "#         print(f\" -> 正在解压 '{package}'...\")\n",
    "#         with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(extract_dir)\n",
    "        \n",
    "#         os.remove(zip_path)\n",
    "#         print(f\" -> '{package}' 准备就绪！\\n\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"处理 '{package}' 时发生错误: {e}\")\n",
    "#         if os.path.exists(zip_path):\n",
    "#             os.remove(zip_path)\n",
    "\n",
    "# print(\"--- 所有NLTK依赖包已处理完毕 ---\")\n",
    "\n",
    "# # =================================================================\n",
    "# # |             !!! 实验结束后记得取消加速 !!!                     |\n",
    "# # =================================================================\n",
    "# print(\"\\n重要提示：下载任务完成后，为避免影响其他网络连接，\")\n",
    "# print(\"您可以在终端中运行 'unset http_proxy && unset https_proxy' 来取消加速。\")\n",
    "# # =================================================================\n",
    "\n",
    "# import os\n",
    "# import zipfile\n",
    "\n",
    "# print(\"--- 开始离线安装NLTK数据包 ---\")\n",
    "\n",
    "# # --- NLTK数据包的目标安装路径 ---\n",
    "# nltk_data_path = os.path.expanduser('~/nltk_data')\n",
    "# print(f\"NLTK数据将被解压到: {nltk_data_path}\\n\")\n",
    "\n",
    "# # --- 定义包名、zip文件名及其对应的目标子目录 ---\n",
    "# packages_to_unzip = {\n",
    "#     'averaged_perceptron_tagger': ('averaged_perceptron_tagger.zip', 'taggers'),\n",
    "#     'stopwords': ('stopwords.zip', 'corpora'),\n",
    "#     'omw-1.4': ('omw-1.4.zip', 'corpora'),\n",
    "#     'universal_tagset': ('universal_tagset.zip', 'taggers'),\n",
    "#     'wordnet': ('wordnet.zip', 'corpora'),\n",
    "#     'punkt': ('punkt.zip', 'tokenizers')\n",
    "# }\n",
    "\n",
    "# # --- 循环检查、解压并清理 ---\n",
    "# all_successful = True\n",
    "# for package_name, (zip_filename, subdir) in packages_to_unzip.items():\n",
    "    \n",
    "#     # zip文件在我们项目根目录下的路径\n",
    "#     # '..' 代表 notebooks 文件夹的上一级目录\n",
    "#     zip_path_in_project = os.path.join('..', zip_filename) \n",
    "\n",
    "#     # 最终解压后的文件夹路径\n",
    "#     extract_dir = os.path.join(nltk_data_path, subdir)\n",
    "#     final_path = os.path.join(extract_dir, package_name)\n",
    "\n",
    "#     print(f\"处理: {package_name}\")\n",
    "\n",
    "#     # 检查zip文件是否存在\n",
    "#     if not os.path.exists(zip_path_in_project):\n",
    "#         print(f\" -> 错误: 未在项目根目录找到 '{zip_filename}'。请确保文件已上传。\")\n",
    "#         all_successful = False\n",
    "#         continue\n",
    "\n",
    "#     # 如果目标文件夹已存在，则跳过\n",
    "#     if os.path.exists(final_path):\n",
    "#          print(f\" -> '{package_name}' 已经存在，跳过。\")\n",
    "#          continue\n",
    "    \n",
    "#     # 确保目标文件夹存在\n",
    "#     os.makedirs(extract_dir, exist_ok=True)\n",
    "    \n",
    "#     try:\n",
    "#         # 解压缩\n",
    "#         print(f\" -> 正在将 '{zip_filename}' 解压到 '{extract_dir}'...\")\n",
    "#         with zipfile.ZipFile(zip_path_in_project, 'r') as zip_ref:\n",
    "#             zip_ref.extractall(extract_dir)\n",
    "#         print(f\" -> '{package_name}' 解压成功！\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\" -> 解压时发生错误: {e}\")\n",
    "#         all_successful = False\n",
    "\n",
    "# if all_successful:\n",
    "#     print(\"\\n--- 所有NLTK依赖包已成功离线安装！---\")\n",
    "# else:\n",
    "#     print(\"\\n--- 部分NLTK依赖包安装失败，请检查错误信息。 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AHP-Env)",
   "language": "python",
   "name": "ahp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
