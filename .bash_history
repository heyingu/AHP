python --version
python3 -m venv ahp_env
source ahp_env/bin/activate
pip list
pip install -r requirements.txt
pip install --upgrade pip
pip install -r requirements.txt
pip list
source ahp_env/bin/activate
cd ~
source ahp_env/bin/activate
pip list
pip install ipykernel
python -m ipykernel install --user --name=ahp_env --display-name="Python (AHP-Env)"
source ahp_env/bin/activate
pip install ipywidgets
ping www.baidu.com
source ahp_env/bin/activate
cd ~
source ahp_env/bin/activate
huggingface-cli login
# 这个命令可能需要root权限，或者根据您的系统提示操作
sudo apt-get update && sudo apt-get install git-lfs
git lfs install
git clone https://hf-mirror.com/lmsys/vicuna-7b-v1.5
mkdir src/models
mkdir src/components
mkdir src/pruning
mkdir src/utils
mkdir src/attacks
source ahp_env/bin/activate
rm -rf vicuna-7b-v1.5
huggingface-cli download --repo-type model --endpoint https://hf-mirror.com lmsys/vicuna-7b-v1.5 --local-dir vicuna-7b-v1.5
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download lmsys/vicuna-7b-v1.5 --local-dir vicuna-7b-v1.5
source ahp_env/bin/activate
rm -rf vicuna-7b-v1.5
cd /root/autodl-tmp
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download lmsys/vicuna-7b-v1.5 --local-dir vicuna-7b-v1.5
cd ~
pip install textattack
pip install --upgrade pip setuptools wheel
pip install textattack
source ahp_env/bin/activate
pip install numpy
pip install textattack
# 这个命令可能需要您输入密码，因为它是在系统层面安装软件
sudo apt-get update && sudo apt-get install -y build-essential python3-dev
pip install textattack
# 这个命令的含义是：安装 textattack，并且强制要求 numpy 的版本必须是 1.26 或更新
pip install "numpy>=1.26" textattack
pip install "scipy>=1.10"
pip install textattack
pip install textattack==0.3.9
pip install -r requirements-textattack.txt
pip install --no-deps textattack==0.3.9
cd ~
source ahp_env/bin/activate
pip install jieba
pip install OpenHowNet
pip install num2words
pip install num2words word2number
source ahp_env/bin/activate
cd .cache
git init
git config --global user.name "heyingu"
git config --global user.email "2665546926@qq.com"
touch .gitignore
echo "__pycache__/"
echo ".ipynb_checkpoints/"
echo "ahp_env/"
git add .
touch .gitignore
echo "__pycache__/" >> .gitignore
echo ".ipynb_checkpoints/" >> .gitignore
git -help
git  --help
git add .
git init
touch .gitignore
echo "__pycache__/"
echo ".ipynb_checkpoints/"
echo “ahp_env/”
echo "ahp-env"
echo "auto-tmp/"
echo "nltk_data/"
echo "miniconda3/"
git add .
df -h
du -sh /root/miniconda3/pkgs/ && rm -rf /root/miniconda3/pkgs/*      # conda的历史包
du -sh /root/.local/share/Trash && rm -rf /root/.local/share/Trash   # jupyterlab的回收站
ls -alh
du -sh
ls -alh
du -sh .local
ls -alh
du -sh .git
du -sh /root/miniconda3/pkgs/
du -sh /root/miniconda3/pkgs/ && rm -rf /root/miniconda3/pkgs/*
rm -rf /root/miniconda3/pkgs/*
du -sh /root/.local/share/Trash
rm -rf .git
du -sh *
# 清理 apt 缓存
sudo apt-get clean
# 清理 pip 缓存
pip cache purge
git init
cd .gitignore
touch .gitignore
cd .gitignore
cat .gitignore
echo "ahp_env"
echo "miniconda3"
echo "autodl-pub/"
cat .gitignore
echo "miniconda3/"
echo "nltk_data/"
cat .gitignore
echo "autodl-tmp/" >> .gitignore
echo "ahp_env/" >> .gitignore
echo "miniconda3/" >> .gitignore
echo "autodl-pub/" >> .gitignore
echo "nltk_data/" >> .gitignore
cat .gitignore
git add .
git commit -m "Initial commit"
git remote add origin https://github.com/heyingu/AHP.git
git push -u origin main
git branch
git branch -m main
git branch
git push -u origin main
git config --global http.version HTTP/1.1
git push -u origin main
git config --global http.version HTTP/1.1
git push -u origin main
git config --global http.postBuffer 524288000
git push
git push -u origin main
ssh-keygen -t rsa -b 4096 -C "2665546926@qq.com"
cat ~/.ssh/id_rsa.pub
git remote set-url origin git@github.com:heyingu/AHP.git
git push
git push -u origin main
git reset --soft HEAD~1
cat .gitignore
ls -alh
du -sh *
rm -rf .git
git init
git branch -m main
cat .gitignore
git ls-files
cat .gitignore
git add .
git commit -m "Initial commit"
git remote add origin git@github.com:heyingu/AHP.git
git push -u origin main
du -sh *
ls -alh
du -sh .git
du -sh /root/.cache
rm -rf .git
git init
git branch -m main
cat .gitignore
echo ".cache/" >> .gitignore
cat .gitignore
git add .
git commit -m "Initial commit"
git remote add origin git@github.com:heyingu/AHP.git
git push -u origin main
source /etc/network_turbo
cd autodl-tmp
rm -rf alpaca-lora-7b
git clone https://huggingface.co/circulus/alpaca-7b
python model_download.py
python model_download.py
cd ~
pip install huggingface_hub
pip unstall huggingface_hub
conda activate ahp_env
conda inti
conda init
conda activate ahp_env
cd ~
conda activate ahp_env
conda init
conda activate ahp_env
source ahp_env/bin/activate
pip install huggingface_hub
python model_download.py
cd src/models/
python model_download.py
rm -rf alpaca-lora-7b
python model_download.py
cd ~
source ahp_env/bin/activate
pip unstall huggingface_hub install -i https://pypi.tuna.tsinghua.edu.cn/simple --force-reinstall "textattack[tensorflow,torch,flair]==0.3.9" num2words word2number
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --force-reinstall "textattack[tensorflow,torch,flair]==0.3.9" num2words word2number
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple tensorflow_hub
git add .
source ~/.bashrc
ls -alh
du -sh .git
du -sh 
du -sh ahp_env
du -sh src
du -sh 
du -sh .cache
du -h
# 只看一级子目录的大小
du -h --max-depth=1
du -h --max-depth=1 ~/.cache
# 使用 huggingface-cli
huggingface-cli scan-cache
# 上面的命令会扫描并让你交互式地选择删除哪些缓存# 使用 huggingface-cli
huggingface-cli scan-cache
# 上面的命令会扫描并让你交互式地选择删除哪些缓
du -h --max-depth=1 ~/.cache
mv ~/.cache /root/autodl-tmp/cache
ln -s /root/autodl-tmp/cache ~/.cache
ls -l ~
ls -alh
source ~/.bashrc
conda create -n ahp_s python=3.10 -y
cd ~
conda activate ahp_s
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple     transformers     accelerate     bitsandbytes     sentence-transformers     scikit-learn     pandas     numpy     tqdm     jupyterlab     ipywidgets
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple     textattack     num2words     word2number     tensorflow_hub
python -m ipykernel install --user --name=ahp_s --display-name="Python (ahp_s)"
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip list
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121
pip install --upgrade --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121
pip3 install torch torchvision
pip listh
pip list
pip unstall torch
pip uninstall torch
pip uninstall torch torchvision torchaudio
pip3 install torch torchvision
cd ~
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128
conda activate ahp_s
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128
git add .
git init
git add .
source ahp_env/bin/activate
cd ~
source ahp_env/bin/activate
pip install num2words
pip install -i https://pypi.org/simple num2words
git commit -m "four"
cd /root/autodl=tmp
cd /root/autodl-tmp
zip -r circulus_alpaca-7b.zip circulus_alpaca-7b/
source ahp_env/bin/activate
pip install tiktoken+
pip install tiktoken
ls -lh /root/autodl-tmp/alpaca-native/tokenizer.model
sudo apt update
sudo apt install git-lfs
git lfs install
cd /root/autodl-tmp/alpaca-native
git lfs pull
ls -lh /root/autodl-tmp/circulus_alpaca-7b/tokenizer.model
cd ~
cd ~ls -lh /root/autodl-tmp/circulus_alpaca-7b/tokenizer.model
ls -lh /root/autodl-tmp/circulus_alpaca-7b/tokenizer.model
cd /root/autodl-tmp/alpaca-native
cd ~
ls -lh /root/autodl-tmp/alpaca-native/tokenizer.model
pip install huggingface_hub
huggingface-cli download alpaca-native tokenizer.model \
huggingface-cli download chavinlo/alpaca-native tokenizer.model \
~/.bashrc
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download --resume-download chavinlo/alpaca-native --local-dir /root/autodl-tmp/alpaca-native 
ls -lh /root/autodl-tmp/circulus_alpaca-7b/tokenizer.model
ls -lh /root/autodl-tmp/alpaca-native/tokenizer.model
huggingface-cli download --repo-type dataset --resume-download fancyzhx/ag_news --local-dir dataset
source ahp_env/bin/activate
wget https://hf-mirror.com/hfd/hfd.shchmod a+x hfd.sh
export HF_ENDPOINT=https://hf-mirror.com
wget https://hf-mirror.com/hfd/hfd.shchmod a+x hfd.sh
./hfd.sh fancyzhx/ag_news dataset
wget https://hf-mirror.com/hfd/hfd.sh
chmod a+x hfd.sh
./hfd.sh fancyzhx/ag_news dataset
hfd fancyzhx/ag_news dataset
./hfd.sh fancyzhx/ag_news dataset
hfd fancyzhx/ag_news --dataset
./hfd.sh fancyzhx/ag_news --dataset
pip install aria2c
huggingface-cli download --repo-type dataset --resume-download fancyzhx/ag_news --local-dir dataset
source ahp_env/bin/activate
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download --resume-download cross-encoder/nli-roberta-base --local-dir autodl-tmp
source ahp_env/bin/activate
export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download --resume-download cross-encoder/nli-roberta-base --local-dir autodl-tmp/cache/huggingface/hub/models--cross-encoder--nli-roberta-base
source ahp_env/bin/activate
git add .
git commit -m "8"
git push
cd autodl-tmp
cd cache
ls -alh
cd textattack
ls -alh
cd ~
cd nltk_data
python -m nltk.downloader punkt_tab
